{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction of Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cite From Keras' [Official Website](https://keras.io/):** *Keras is a high-level neural networks API, written in Python and capable of running on top of TensorFlow, CNTK, or Theano. It was developed with a focus on enabling fast experimentation. Being able to go from idea to result with the least possible delay is key to doing good research.*\n",
    "\n",
    "Keras is essentially a set of functions that calling a neural network backend (TensorFlow, CNTK, or Theano) to do related learning jobs. Keras has a good taste of design. After you understand the fundamentals in deep learning, you'll find Keras is very intuitive to use. Besides, Keras also has a very active community and provides complete documentations. **If you have something don't understand in the procss, I highly recommend you to read its documents at first.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation and Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This simplest way to setup Keras is through **pip/pip3** (you can find more details [here](https://keras.io/#installation)):\n",
    "\n",
    "```bash\n",
    ">> pip3 install tensorflow Keras\n",
    "```\n",
    "\n",
    "After successfully install Keras, we can import related classes into notebook's workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/Cellar/python3/3.5.2_3/Frameworks/Python.framework/Versions/3.5/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we import **sequential** model, which is a model with each elemental unit connected sequentially. This structure is simple but very common in deep learning. Besides, we includes different kinds of layers, which is the fundamental unit in deep learninng. Among them, **Dense** is the linear transformation layer, while **Conv2D** corresponds to convolutional transformation. **MaxPooling2D** is a layer that down-samples data in 2D with *max* operation. **Flatten** is a layer reshape the data to fit for linear transformation. You can find more detail for each layer in [documents](https://keras.io/layers/about-keras-layers/).\n",
    "\n",
    "There is also a very good [explanation](https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/) of convolutional neural network (CNN), which is what we would use in this demo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain Dataset from Internet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset we are going to deal with is MNIST, a handwriten digits dataset which you have seen before. It's simple, however, we need it in the form that match assumptions of Keras (which can be a hugh amount of week for your own dataset). Here, we directly fetch this popular dataset from Keras' dataset library. You can also find [other datasets](https://keras.io/datasets/) in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "# download data from internet (only the first time) and split it into training and testing set\n",
    "(imgTrain, labelTrain), (imgTest, labelTest) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, our work haven't done yet. There are two things we need to do:\n",
    "1. **Conv2D** layers only deal with 3D samples, which is for color images, however MNIST only have two dimensions. So we need to reshape it into fake 3D samples with the length of 3rd dimension being 1.\n",
    "2. The value of each pixel in the dataset is integers from 0 to 255, which is not good for calculation. Here, we'll map them to float numbers in the range of $[0,1]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing you should know is that different backend use different dimension order. So, here I use a conditional process to reshape the data. However, if you are confident to which one your backend use, you can directly reshape your data into corresponding form. In my case, I use **TensorFlow** as the backend. It puts dimension of color channel to the last dimension in *ndarray*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set in shape of  (60000, 28, 28, 1)  with element type  <class 'float'>\n",
      "Testing set in shape of   (10000, 28, 28, 1)  with element type  <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "imgRows, imgCols = 28, 28 # size of source image\n",
    "\n",
    "# reshape images in training and testing set into fake 3D\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    imgTrain = imgTrain.reshape(imgTrain.shape[0], 1, imgRows, imgCols)\n",
    "    imgTest  = imgTest.reshape(imgTest.shape[0], 1, imgRows, imgCols)\n",
    "    smpSize  = (1, imgRows, imgCols)\n",
    "else:\n",
    "    imgTrain = imgTrain.reshape(imgTrain.shape[0], imgRows, imgCols, 1)\n",
    "    imgTest  = imgTest.reshape(imgTest.shape[0], imgRows, imgCols, 1)\n",
    "    smpSize  = (imgRows, imgCols, 1)\n",
    "\n",
    "# convert pixels to floats and map them into range of [0,1]\n",
    "imgTrain = imgTrain.astype('float') / 255\n",
    "imgTest  = imgTest.astype('float') / 255\n",
    "\n",
    "# show shape and type of our datasets\n",
    "print('Training set in shape of ', imgTrain.shape, ' with element type ', type(imgTrain.item(0)))\n",
    "print('Testing set in shape of  ', imgTest.shape, ' with element type ', type(imgTrain.item(0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have done the preprocessing for image part. We also need to do one last thing for labels to fit for requirement of learning process. Basically, we are going to convert label of each image, such as $1$, in to one-hot vectors ([here](https://hackernoon.com/what-is-one-hot-encoding-why-and-when-do-you-have-to-use-it-e3c6186d008f) is a good blog to explain it in detail), like $[0, 1, 0, 0, 0, 0, 0, 0, 0, 0]$. Becuase this operation is very common in classification, there is a function in Keras to deal with it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ncat = 10 # number of categories in our problem\n",
    "\n",
    "# convert labels to one-hot vectors\n",
    "onehotTrain = keras.utils.to_categorical(labelTrain, ncat)\n",
    "onehotTest  = keras.utils.to_categorical(labelTest, ncat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For sequential model, the building process is essetially add different layers sequentially. **Here, I just use a naive structure. It will not achive best performance, however, enough to show the procedure.** You should try different structures to compare the performance. You can find the standard structure online, but, you also can try different ones as your idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# claim a sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# add first layer as convolution transformation with 32 filters of size [3, 3]\n",
    "# - 'activation' is the non-linear tranform used in neural network, a common one is 'sigmoid'\n",
    "# - for the first layer, you also need to claim size of input samples\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=smpSize))\n",
    "# add max-pooling layer\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# add flatten layer to reshape data to fit for linear transform\n",
    "model.add(Flatten())\n",
    "# linear transofrm with activation of softmax\n",
    "model.add(Dense(ncat, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to compile the model. This is the limitation of current packages in deep learning : lack of dynamic features, which is also a hot topic in related community to create extensions to support dynamic feature. However, it still in development, you can try them, but be aware of there should be some problems haven't solved yet.\n",
    "\n",
    "In the compilation, there are several options you can choose:\n",
    "1. **loss**, the loss function (or objective function) describe how you evaluate the difference between truth labels with your model's prediction\n",
    "2. **optimizer**, the mehtod your model will use in optimization, you can use default settings currently\n",
    "3. **metrics**, is the evaluation method in showing train progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model with MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training in Keras uses function **fit**. Basically, it just provide training and testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 9s 142us/step - loss: 2.2997 - acc: 0.1161 - val_loss: 2.2905 - val_acc: 0.1135\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 8s 137us/step - loss: 2.0542 - acc: 0.4746 - val_loss: 1.4151 - val_acc: 0.7744\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 8s 138us/step - loss: 0.8812 - acc: 0.8138 - val_loss: 0.5808 - val_acc: 0.8583\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x118445dd8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(imgTrain, onehotTrain, validation_data=(imgTest, onehotTest), batch_size=128, epochs=3, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let see the result of training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss     : 0.580776459026\n",
      "Test accuracy : 0.8583\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(imgTest, onehotTest, verbose=0)\n",
    "print('Test loss     :', score[0])\n",
    "print('Test accuracy :', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You see, thei model only gets accuracy of 85.8%. It's the time for you to improve it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
