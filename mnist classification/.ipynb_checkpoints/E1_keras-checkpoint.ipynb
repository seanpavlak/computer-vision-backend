{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.layers import Activation, Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_mnist_data():\n",
    "    # the data, split between train and test sets\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    \n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "        x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "        input_shape = (1, img_rows, img_cols)\n",
    "    else:\n",
    "        x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "        x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "        input_shape = (img_rows, img_cols, 1)\n",
    "    \n",
    "    x_train = x_train.astype('float32')/255\n",
    "    x_test = x_test.astype('float32')/255\n",
    "    \n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print(x_train.shape[0], 'train samples')\n",
    "    print(x_test.shape[0], 'test samples')\n",
    "    \n",
    "    # convert class vectors to binary class matrices\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "    \n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_score_mnist_data(feature_layers, classification_layers, epochs, loss, optimizer):\n",
    "    (x_train, y_train), (x_test, y_test) = load_mnist_data()\n",
    "\n",
    "    model = Sequential(feature_layers + classification_layers)\n",
    "\n",
    "    model.compile(\n",
    "    loss=loss, \n",
    "    optimizer=optimizer, \n",
    "    metrics=['accuracy'])\n",
    "\n",
    "    model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    verbose=1,\n",
    "    validation_data=(x_test, y_test))\n",
    "    \n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    \n",
    "    return score, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_layers = [\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classification_layers = [\n",
    "    Dense(num_classes, activation='softmax')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_original = []\n",
    "loss=keras.losses.categorical_crossentropy\n",
    "optimizer=keras.optimizers.Adadelta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 11s 182us/step - loss: 0.2159 - acc: 0.9370 - val_loss: 0.0966 - val_acc: 0.9733\n",
      "Test loss: 0.096591734235\n",
      "Test accuracy: 0.9733\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "score = fit_score_mnist_data(feature_layers, classification_layers, epochs, loss, optimizer)\n",
    "score_original.append(score[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improved CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_layers = [\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)), \n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Dropout(.25),\n",
    "    Flatten()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classification_layers = [\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_improved = []\n",
    "loss=keras.losses.categorical_crossentropy\n",
    "optimizer=keras.optimizers.Adadelta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 100s 2ms/step - loss: 0.2136 - acc: 0.9352 - val_loss: 0.0510 - val_acc: 0.9836\n",
      "Test loss: 0.0510165721905\n",
      "Test accuracy: 0.9836\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "score = fit_score_mnist_data(feature_layers, classification_layers, epochs, loss, optimizer)\n",
    "score_improved.append(score[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_layers = [\n",
    "    Conv2D(32, (3, 3), padding='same', input_shape=(28, 28, 1)),\n",
    "    Activation('relu'),\n",
    "    Conv2D(32, (3, 3), padding='same'),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Dropout(.25),\n",
    "    Flatten()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classification_layers = [\n",
    "    Dense(128),\n",
    "    Activation('relu'),\n",
    "    Dropout(.50),\n",
    "    Dense(num_classes),\n",
    "    Activation('softmax')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_sgd = []\n",
    "loss=keras.losses.categorical_crossentropy\n",
    "optimizer=SGD(clipnorm=10000, clipvalue=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 93s 2ms/step - loss: 0.6740 - acc: 0.7819 - val_loss: 0.2118 - val_acc: 0.9380\n",
      "Test loss: 0.211838701645\n",
      "Test accuracy: 0.938\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "score = fit_score_mnist_data(feature_layers, classification_layers, epochs, loss, optimizer)\n",
    "score_sgd.append(score[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Sigmoid Activation & Average Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_layers = [\n",
    "    Conv2D(32, (3, 3), padding='same', input_shape=(28, 28, 1)),\n",
    "    Activation('sigmoid'),\n",
    "    Conv2D(32, (3, 3), padding='same'),\n",
    "    Activation('sigmoid'),\n",
    "    AveragePooling2D(pool_size=(2,2)),\n",
    "    Dropout(.25),\n",
    "    Flatten()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classification_layers = [\n",
    "    Dense(128),\n",
    "    Activation('sigmoid'),\n",
    "    Dropout(.50),\n",
    "    Dense(num_classes),\n",
    "    Activation('softmax')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_sigmoid = []\n",
    "loss=keras.losses.categorical_crossentropy\n",
    "optimizer=SGD(clipnorm=10000, clipvalue=10000, lr=0.1, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 85s 1ms/step - loss: 2.3561 - acc: 0.1016 - val_loss: 2.3036 - val_acc: 0.1032\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 85s 1ms/step - loss: 2.3084 - acc: 0.1035 - val_loss: 2.3246 - val_acc: 0.1135\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 75s 1ms/step - loss: 2.3088 - acc: 0.1038 - val_loss: 2.3075 - val_acc: 0.1135\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 84s 1ms/step - loss: 2.3079 - acc: 0.1052 - val_loss: 2.3048 - val_acc: 0.1028\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 87s 1ms/step - loss: 2.3082 - acc: 0.1035 - val_loss: 2.3074 - val_acc: 0.1009\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 87s 1ms/step - loss: 2.3083 - acc: 0.1045 - val_loss: 2.3068 - val_acc: 0.1135\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 82s 1ms/step - loss: 2.3085 - acc: 0.1031 - val_loss: 2.3131 - val_acc: 0.1135\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 93s 2ms/step - loss: 2.3078 - acc: 0.1038 - val_loss: 2.3077 - val_acc: 0.1135\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 85s 1ms/step - loss: 2.3083 - acc: 0.1045 - val_loss: 2.3132 - val_acc: 0.0980\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 84s 1ms/step - loss: 2.3081 - acc: 0.1059 - val_loss: 2.3048 - val_acc: 0.1028\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 85s 1ms/step - loss: 2.3078 - acc: 0.1035 - val_loss: 2.3146 - val_acc: 0.1010\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 84s 1ms/step - loss: 0.9616 - acc: 0.6601 - val_loss: 0.2774 - val_acc: 0.9096\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 85s 1ms/step - loss: 0.3836 - acc: 0.8803 - val_loss: 0.1535 - val_acc: 0.9531\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 85s 1ms/step - loss: 0.2889 - acc: 0.9108 - val_loss: 0.1282 - val_acc: 0.9627\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 86s 1ms/step - loss: 0.2356 - acc: 0.9279 - val_loss: 0.0964 - val_acc: 0.9707\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 84s 1ms/step - loss: 0.2025 - acc: 0.9376 - val_loss: 0.0795 - val_acc: 0.9747\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 86s 1ms/step - loss: 0.1810 - acc: 0.9440 - val_loss: 0.0772 - val_acc: 0.9769\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 85s 1ms/step - loss: 0.1659 - acc: 0.9482 - val_loss: 0.0688 - val_acc: 0.9793\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 828s 14ms/step - loss: 0.1528 - acc: 0.9532 - val_loss: 0.0646 - val_acc: 0.9803\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 82s 1ms/step - loss: 0.1352 - acc: 0.9582 - val_loss: 0.0587 - val_acc: 0.9819\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 87s 1ms/step - loss: 0.1278 - acc: 0.9605 - val_loss: 0.0560 - val_acc: 0.9837\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 86s 1ms/step - loss: 0.1157 - acc: 0.9641 - val_loss: 0.0507 - val_acc: 0.9848\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 86s 1ms/step - loss: 0.1064 - acc: 0.9665 - val_loss: 0.0505 - val_acc: 0.9859\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 84s 1ms/step - loss: 0.1021 - acc: 0.9672 - val_loss: 0.0488 - val_acc: 0.9855\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 87s 1ms/step - loss: 0.0986 - acc: 0.9691 - val_loss: 0.0466 - val_acc: 0.9857\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 87s 1ms/step - loss: 0.0922 - acc: 0.9710 - val_loss: 0.0513 - val_acc: 0.9845\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 87s 1ms/step - loss: 0.0883 - acc: 0.9722 - val_loss: 0.0446 - val_acc: 0.9866\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 87s 1ms/step - loss: 0.0878 - acc: 0.9734 - val_loss: 0.0418 - val_acc: 0.9872\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 81s 1ms/step - loss: 0.0807 - acc: 0.9745 - val_loss: 0.0422 - val_acc: 0.9869\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 86s 1ms/step - loss: 0.0764 - acc: 0.9759 - val_loss: 0.0382 - val_acc: 0.9880\n",
      "Test loss: 0.0382246035573\n",
      "Test accuracy: 0.988\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "score = fit_score_mnist_data(feature_layers, classification_layers, epochs, loss, optimizer)\n",
    "score_sigmoid.append(score[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJLX+P0kw351MXd68AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x123dad588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([0.1016, 0.1035, 0.1038, 0.1052, 0.1035, 0.1045, 0.1031, 0.1038, 0.1045, 0.1059, 0.1035, 0.6601, 0.8803, 0.9108, 0.9279, 0.9376, 0.9440, 0.9482, 0.9532, 0.9582, 0.9605, 0.9641, 0.9665, 0.9672, 0.9691, 0.9710, 0.9722, 0.9734, 0.9745, 0.9759, 0.988], 'ro')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# MSE Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_layers = [\n",
    "    Conv2D(32, (3, 3), padding='same', input_shape=(28, 28, 1)),\n",
    "    Activation('sigmoid'),\n",
    "    Conv2D(32, (3, 3), padding='same'),\n",
    "    Activation('sigmoid'),\n",
    "    AveragePooling2D(pool_size=(2,2)),\n",
    "    Dropout(.25),\n",
    "    Flatten()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classification_layers = [\n",
    "    Dense(128),\n",
    "    Activation('sigmoid'),\n",
    "    Dropout(.50),\n",
    "    Dense(num_classes),\n",
    "    Activation('softmax')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_mse = []\n",
    "loss='mean_squared_error'\n",
    "optimizer=SGD(clipnorm=10000, clipvalue=10000, lr=0.1, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 84s 1ms/step - loss: 0.0901 - acc: 0.1068 - val_loss: 0.0900 - val_acc: 0.1135\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 85s 1ms/step - loss: 0.0900 - acc: 0.1120 - val_loss: 0.0900 - val_acc: 0.1135\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 84s 1ms/step - loss: 0.0900 - acc: 0.1124 - val_loss: 0.0900 - val_acc: 0.1135\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 84s 1ms/step - loss: 0.0900 - acc: 0.1117 - val_loss: 0.0900 - val_acc: 0.1135\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 84s 1ms/step - loss: 0.0900 - acc: 0.1124 - val_loss: 0.0900 - val_acc: 0.1135\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 82s 1ms/step - loss: 0.0900 - acc: 0.1124 - val_loss: 0.0900 - val_acc: 0.1135\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 84s 1ms/step - loss: 0.0900 - acc: 0.1123 - val_loss: 0.0900 - val_acc: 0.1135\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 85s 1ms/step - loss: 0.0900 - acc: 0.1122 - val_loss: 0.0900 - val_acc: 0.1135\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 85s 1ms/step - loss: 0.0900 - acc: 0.1124 - val_loss: 0.0900 - val_acc: 0.1135\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 84s 1ms/step - loss: 0.0900 - acc: 0.1124 - val_loss: 0.0900 - val_acc: 0.1135\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 85s 1ms/step - loss: 0.0900 - acc: 0.1124 - val_loss: 0.0900 - val_acc: 0.1135\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 85s 1ms/step - loss: 0.0900 - acc: 0.1124 - val_loss: 0.0900 - val_acc: 0.1135\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 85s 1ms/step - loss: 0.0900 - acc: 0.1124 - val_loss: 0.0900 - val_acc: 0.1135\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 85s 1ms/step - loss: 0.0900 - acc: 0.1124 - val_loss: 0.0900 - val_acc: 0.1135\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 85s 1ms/step - loss: 0.0900 - acc: 0.1124 - val_loss: 0.0900 - val_acc: 0.1135\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 86s 1ms/step - loss: 0.0900 - acc: 0.1124 - val_loss: 0.0900 - val_acc: 0.1135\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 85s 1ms/step - loss: 0.0900 - acc: 0.1121 - val_loss: 0.0900 - val_acc: 0.1135\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 86s 1ms/step - loss: 0.0900 - acc: 0.1123 - val_loss: 0.0900 - val_acc: 0.1135\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 86s 1ms/step - loss: 0.0900 - acc: 0.1124 - val_loss: 0.0900 - val_acc: 0.1135\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 86s 1ms/step - loss: 0.0900 - acc: 0.1123 - val_loss: 0.0900 - val_acc: 0.1135\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 86s 1ms/step - loss: 0.0900 - acc: 0.1124 - val_loss: 0.0900 - val_acc: 0.1135\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 90s 1ms/step - loss: 0.0900 - acc: 0.1123 - val_loss: 0.0900 - val_acc: 0.1135\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 89s 1ms/step - loss: 0.0900 - acc: 0.1123 - val_loss: 0.0900 - val_acc: 0.1135\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 88s 1ms/step - loss: 0.0900 - acc: 0.1124 - val_loss: 0.0900 - val_acc: 0.1135\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 92s 2ms/step - loss: 0.0900 - acc: 0.1123 - val_loss: 0.0900 - val_acc: 0.1135\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 87s 1ms/step - loss: 0.0900 - acc: 0.1123 - val_loss: 0.0900 - val_acc: 0.1135\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 88s 1ms/step - loss: 0.0900 - acc: 0.1123 - val_loss: 0.0900 - val_acc: 0.1135\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 88s 1ms/step - loss: 0.0900 - acc: 0.1123 - val_loss: 0.0900 - val_acc: 0.1135\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 89s 1ms/step - loss: 0.0900 - acc: 0.1122 - val_loss: 0.0900 - val_acc: 0.1135\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 87s 1ms/step - loss: 0.0900 - acc: 0.1123 - val_loss: 0.0900 - val_acc: 0.1135\n",
      "Test loss: 0.0899600203276\n",
      "Test accuracy: 0.1135\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "score = fit_score_mnist_data(feature_layers, classification_layers, epochs, loss, optimizer)\n",
    "score_mse.append(score[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n11uyS4PJEKgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x124cd9c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([0.1116, 0.1123, 0.1122, 0.1123, 0.1124, 0.1123, 0.1123, 0.1122, 0.1122, 0.1123, 0.1124, 0.1123, 0.1123, 0.1124, 0.1122, 0.1122, 0.1123, 0.1125, 0.1120, 0.1145, 0.1340, 0.6515, 0.8678, 0.8918, 0.9050, 0.9351], 'ro')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
