{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.layers import Activation, Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_mnist_data():\n",
    "    # the data, split between train and test sets\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    \n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "        x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "        input_shape = (1, img_rows, img_cols)\n",
    "    else:\n",
    "        x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "        x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "        input_shape = (img_rows, img_cols, 1)\n",
    "    \n",
    "    x_train = x_train.astype('float32')/255\n",
    "    x_test = x_test.astype('float32')/255\n",
    "    \n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print(x_train.shape[0], 'train samples')\n",
    "    print(x_test.shape[0], 'test samples')\n",
    "    \n",
    "    # convert class vectors to binary class matrices\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "    \n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_score_mnist_data(feature_layers, classification_layers, epochs, loss, optimizer):\n",
    "    (x_train, y_train), (x_test, y_test) = load_mnist_data()\n",
    "\n",
    "    model = Sequential(feature_layers + classification_layers)\n",
    "\n",
    "    model.compile(\n",
    "    loss=loss, \n",
    "    optimizer=optimizer, \n",
    "    metrics=['accuracy'])\n",
    "\n",
    "    model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    verbose=1,\n",
    "    validation_data=(x_test, y_test))\n",
    "    \n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    \n",
    "    return score, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_layers = [\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classification_layers = [\n",
    "    Dense(num_classes, activation='softmax')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_original = []\n",
    "loss = keras.losses.categorical_crossentropy\n",
    "optimizer = keras.optimizers.Adadelta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 11s 182us/step - loss: 0.2159 - acc: 0.9370 - val_loss: 0.0966 - val_acc: 0.9733\n",
      "Test loss: 0.096591734235\n",
      "Test accuracy: 0.9733\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "score = fit_score_mnist_data(feature_layers, classification_layers, epochs, loss, optimizer)\n",
    "score_original.append(score[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improved CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_layers = [\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)), \n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Dropout(.25),\n",
    "    Flatten()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classification_layers = [\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_improved = []\n",
    "loss=keras.losses.categorical_crossentropy\n",
    "optimizer=keras.optimizers.Adadelta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 100s 2ms/step - loss: 0.2136 - acc: 0.9352 - val_loss: 0.0510 - val_acc: 0.9836\n",
      "Test loss: 0.0510165721905\n",
      "Test accuracy: 0.9836\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "score = fit_score_mnist_data(feature_layers, classification_layers, epochs, loss, optimizer)\n",
    "score_improved.append(score[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_layers = [\n",
    "    Conv2D(32, (3, 3), padding='same', input_shape=(28, 28, 1)),\n",
    "    Activation('relu'),\n",
    "    Conv2D(32, (3, 3), padding='same'),\n",
    "    Activation('relu'),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Dropout(.25),\n",
    "    Flatten()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classification_layers = [\n",
    "    Dense(128),\n",
    "    Activation('relu'),\n",
    "    Dropout(.50),\n",
    "    Dense(num_classes),\n",
    "    Activation('softmax')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_sgd = []\n",
    "loss=keras.losses.categorical_crossentropy\n",
    "optimizer=SGD(clipnorm=10000, clipvalue=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 93s 2ms/step - loss: 0.6740 - acc: 0.7819 - val_loss: 0.2118 - val_acc: 0.9380\n",
      "Test loss: 0.211838701645\n",
      "Test accuracy: 0.938\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "score = fit_score_mnist_data(feature_layers, classification_layers, epochs, loss, optimizer)\n",
    "score_sgd.append(score[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Sigmoid Activation & Average Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_layers = [\n",
    "    Conv2D(32, (3, 3), padding='same', input_shape=(28, 28, 1)),\n",
    "    Activation('sigmoid'),\n",
    "    Conv2D(32, (3, 3), padding='same'),\n",
    "    Activation('sigmoid'),\n",
    "    AveragePooling2D(pool_size=(2,2)),\n",
    "    Dropout(.25),\n",
    "    Flatten()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classification_layers = [\n",
    "    Dense(128),\n",
    "    Activation('sigmoid'),\n",
    "    Dropout(.50),\n",
    "    Dense(num_classes),\n",
    "    Activation('softmax')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_sigmoid = []\n",
    "loss=keras.losses.categorical_crossentropy\n",
    "optimizer=SGD(clipnorm=10000, clipvalue=10000, lr=0.1, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 85s 1ms/step - loss: 2.3561 - acc: 0.1016 - val_loss: 2.3036 - val_acc: 0.1032\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 85s 1ms/step - loss: 2.3084 - acc: 0.1035 - val_loss: 2.3246 - val_acc: 0.1135\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 75s 1ms/step - loss: 2.3088 - acc: 0.1038 - val_loss: 2.3075 - val_acc: 0.1135\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 84s 1ms/step - loss: 2.3079 - acc: 0.1052 - val_loss: 2.3048 - val_acc: 0.1028\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 87s 1ms/step - loss: 2.3082 - acc: 0.1035 - val_loss: 2.3074 - val_acc: 0.1009\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 87s 1ms/step - loss: 2.3083 - acc: 0.1045 - val_loss: 2.3068 - val_acc: 0.1135\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 82s 1ms/step - loss: 2.3085 - acc: 0.1031 - val_loss: 2.3131 - val_acc: 0.1135\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 93s 2ms/step - loss: 2.3078 - acc: 0.1038 - val_loss: 2.3077 - val_acc: 0.1135\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 85s 1ms/step - loss: 2.3083 - acc: 0.1045 - val_loss: 2.3132 - val_acc: 0.0980\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 84s 1ms/step - loss: 2.3081 - acc: 0.1059 - val_loss: 2.3048 - val_acc: 0.1028\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 85s 1ms/step - loss: 2.3078 - acc: 0.1035 - val_loss: 2.3146 - val_acc: 0.1010\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 84s 1ms/step - loss: 0.9616 - acc: 0.6601 - val_loss: 0.2774 - val_acc: 0.9096\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 85s 1ms/step - loss: 0.3836 - acc: 0.8803 - val_loss: 0.1535 - val_acc: 0.9531\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 85s 1ms/step - loss: 0.2889 - acc: 0.9108 - val_loss: 0.1282 - val_acc: 0.9627\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 86s 1ms/step - loss: 0.2356 - acc: 0.9279 - val_loss: 0.0964 - val_acc: 0.9707\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 84s 1ms/step - loss: 0.2025 - acc: 0.9376 - val_loss: 0.0795 - val_acc: 0.9747\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 86s 1ms/step - loss: 0.1810 - acc: 0.9440 - val_loss: 0.0772 - val_acc: 0.9769\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 85s 1ms/step - loss: 0.1659 - acc: 0.9482 - val_loss: 0.0688 - val_acc: 0.9793\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 828s 14ms/step - loss: 0.1528 - acc: 0.9532 - val_loss: 0.0646 - val_acc: 0.9803\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 82s 1ms/step - loss: 0.1352 - acc: 0.9582 - val_loss: 0.0587 - val_acc: 0.9819\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 87s 1ms/step - loss: 0.1278 - acc: 0.9605 - val_loss: 0.0560 - val_acc: 0.9837\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 86s 1ms/step - loss: 0.1157 - acc: 0.9641 - val_loss: 0.0507 - val_acc: 0.9848\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 86s 1ms/step - loss: 0.1064 - acc: 0.9665 - val_loss: 0.0505 - val_acc: 0.9859\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 84s 1ms/step - loss: 0.1021 - acc: 0.9672 - val_loss: 0.0488 - val_acc: 0.9855\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 87s 1ms/step - loss: 0.0986 - acc: 0.9691 - val_loss: 0.0466 - val_acc: 0.9857\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 87s 1ms/step - loss: 0.0922 - acc: 0.9710 - val_loss: 0.0513 - val_acc: 0.9845\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 87s 1ms/step - loss: 0.0883 - acc: 0.9722 - val_loss: 0.0446 - val_acc: 0.9866\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 87s 1ms/step - loss: 0.0878 - acc: 0.9734 - val_loss: 0.0418 - val_acc: 0.9872\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 81s 1ms/step - loss: 0.0807 - acc: 0.9745 - val_loss: 0.0422 - val_acc: 0.9869\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 86s 1ms/step - loss: 0.0764 - acc: 0.9759 - val_loss: 0.0382 - val_acc: 0.9880\n",
      "Test loss: 0.0382246035573\n",
      "Test accuracy: 0.988\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "score = fit_score_mnist_data(feature_layers, classification_layers, epochs, loss, optimizer)\n",
    "score_sigmoid.append(score[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJLX+P0kw351MXd68AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x123dad588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([0.1016, 0.1035, 0.1038, 0.1052, 0.1035, 0.1045, 0.1031, 0.1038, 0.1045, 0.1059, 0.1035, 0.6601, 0.8803, 0.9108, 0.9279, 0.9376, 0.9440, 0.9482, 0.9532, 0.9582, 0.9605, 0.9641, 0.9665, 0.9672, 0.9691, 0.9710, 0.9722, 0.9734, 0.9745, 0.9759, 0.988], 'ro')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# MSE Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_layers = [\n",
    "    Conv2D(32, (3, 3), padding='same', input_shape=(28, 28, 1)),\n",
    "    Activation('sigmoid'),\n",
    "    Conv2D(32, (3, 3), padding='same'),\n",
    "    Activation('sigmoid'),\n",
    "    AveragePooling2D(pool_size=(2,2)),\n",
    "    Dropout(.25),\n",
    "    Flatten()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classification_layers = [\n",
    "    Dense(128),\n",
    "    Activation('sigmoid'),\n",
    "    Dropout(.50),\n",
    "    Dense(num_classes),\n",
    "    Activation('softmax')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_mse = []\n",
    "loss='mean_squared_error'\n",
    "optimizer=SGD(clipnorm=10000, clipvalue=10000, lr=0.1, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 84s 1ms/step - loss: 0.0901 - acc: 0.1068 - val_loss: 0.0900 - val_acc: 0.1135\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 85s 1ms/step - loss: 0.0900 - acc: 0.1120 - val_loss: 0.0900 - val_acc: 0.1135\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 84s 1ms/step - loss: 0.0900 - acc: 0.1124 - val_loss: 0.0900 - val_acc: 0.1135\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 84s 1ms/step - loss: 0.0900 - acc: 0.1117 - val_loss: 0.0900 - val_acc: 0.1135\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 84s 1ms/step - loss: 0.0900 - acc: 0.1124 - val_loss: 0.0900 - val_acc: 0.1135\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 82s 1ms/step - loss: 0.0900 - acc: 0.1124 - val_loss: 0.0900 - val_acc: 0.1135\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 84s 1ms/step - loss: 0.0900 - acc: 0.1123 - val_loss: 0.0900 - val_acc: 0.1135\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 85s 1ms/step - loss: 0.0900 - acc: 0.1122 - val_loss: 0.0900 - val_acc: 0.1135\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 85s 1ms/step - loss: 0.0900 - acc: 0.1124 - val_loss: 0.0900 - val_acc: 0.1135\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 84s 1ms/step - loss: 0.0900 - acc: 0.1124 - val_loss: 0.0900 - val_acc: 0.1135\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 85s 1ms/step - loss: 0.0900 - acc: 0.1124 - val_loss: 0.0900 - val_acc: 0.1135\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 85s 1ms/step - loss: 0.0900 - acc: 0.1124 - val_loss: 0.0900 - val_acc: 0.1135\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 85s 1ms/step - loss: 0.0900 - acc: 0.1124 - val_loss: 0.0900 - val_acc: 0.1135\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 85s 1ms/step - loss: 0.0900 - acc: 0.1124 - val_loss: 0.0900 - val_acc: 0.1135\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 85s 1ms/step - loss: 0.0900 - acc: 0.1124 - val_loss: 0.0900 - val_acc: 0.1135\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 86s 1ms/step - loss: 0.0900 - acc: 0.1124 - val_loss: 0.0900 - val_acc: 0.1135\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 85s 1ms/step - loss: 0.0900 - acc: 0.1121 - val_loss: 0.0900 - val_acc: 0.1135\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 86s 1ms/step - loss: 0.0900 - acc: 0.1123 - val_loss: 0.0900 - val_acc: 0.1135\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 86s 1ms/step - loss: 0.0900 - acc: 0.1124 - val_loss: 0.0900 - val_acc: 0.1135\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 86s 1ms/step - loss: 0.0900 - acc: 0.1123 - val_loss: 0.0900 - val_acc: 0.1135\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 86s 1ms/step - loss: 0.0900 - acc: 0.1124 - val_loss: 0.0900 - val_acc: 0.1135\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 90s 1ms/step - loss: 0.0900 - acc: 0.1123 - val_loss: 0.0900 - val_acc: 0.1135\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 89s 1ms/step - loss: 0.0900 - acc: 0.1123 - val_loss: 0.0900 - val_acc: 0.1135\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 88s 1ms/step - loss: 0.0900 - acc: 0.1124 - val_loss: 0.0900 - val_acc: 0.1135\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 92s 2ms/step - loss: 0.0900 - acc: 0.1123 - val_loss: 0.0900 - val_acc: 0.1135\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 87s 1ms/step - loss: 0.0900 - acc: 0.1123 - val_loss: 0.0900 - val_acc: 0.1135\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 88s 1ms/step - loss: 0.0900 - acc: 0.1123 - val_loss: 0.0900 - val_acc: 0.1135\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 88s 1ms/step - loss: 0.0900 - acc: 0.1123 - val_loss: 0.0900 - val_acc: 0.1135\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 89s 1ms/step - loss: 0.0900 - acc: 0.1122 - val_loss: 0.0900 - val_acc: 0.1135\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 87s 1ms/step - loss: 0.0900 - acc: 0.1123 - val_loss: 0.0900 - val_acc: 0.1135\n",
      "Test loss: 0.0899600203276\n",
      "Test accuracy: 0.1135\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "score = fit_score_mnist_data(feature_layers, classification_layers, epochs, loss, optimizer)\n",
    "score_mse.append(score[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n80/8I7gmv8J5nQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1271ae668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([0.1116, 0.1123, 0.1122, 0.1123, 0.1124, 0.1123, 0.1123, 0.1122, 0.1122, 0.1123, 0.1124, 0.1123, 0.1123, 0.1124, 0.1122, 0.1122, 0.1123, 0.1125, 0.1120, 0.1145, 0.1340, 0.6515, 0.8678, 0.8918, 0.9050, 0.9351], 'ro')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
